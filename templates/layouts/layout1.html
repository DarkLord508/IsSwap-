<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>{% block title %}{% endblock %}</title>
    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="/static/css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom CSS -->
    <link href="/static/css/freelancer.css" rel="stylesheet">
    <!-- Custom Fonts -->
    <link href="/static/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>
<body id="page-top" class="index">
    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#page-top">IsSwap?</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#portfolio">Top Stories</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#about">Our Vision</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#contact">Test Section</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    {% block content %}
    {% endblock %}

    <!-- Footer -->
    <footer class="text-center">
        <div class="footer-above">
            <div class="container">
                <div class="row">
                    <div class="footer-col col-md-4">
                        <h3>Location</h3>
                        <p>Jaypee Institute of Information Technology<br>Noida, 201301</p>
                    </div>
                    <div class="footer-col col-md-4">
                        
                    </div>
                    <div class="footer-col col-md-4">
                        <h3>Made By</h3>
                        <p>Aakriti Agarwal<br>Nishit Anand<br>Pallav Gupta<br>Siddhant Wadhwa</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        Made with <svg viewBox="0 0 1792 1792" preserveAspectRatio="xMidYMid meet" xmlns="http://www.w3.org/2000/svg" style="height: 0.8rem;"><path d="M896 1664q-26 0-44-18l-624-602q-10-8-27.5-26T145 952.5 77 855 23.5 734 0 596q0-220 127-344t351-124q62 0 126.5 21.5t120 58T820 276t76 68q36-36 76-68t95.5-68.5 120-58T1314 128q224 0 351 124t127 344q0 221-229 450l-623 600q-18 18-44 18z" fill="#e25555"></path></svg> at home.

                        <!-- Example #6 - JavaScript Console log -->
                        <script>
                        console.info(
                          'Made with %c♥%c in Switzerland',
                          'color: #e25555', 'color: unset'
                        );
                        </script>
                        
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-xs visible-sm">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>
    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Dutch politicians were tricked by a deepfake video chat</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/b.png" class="img-responsive img-centered" alt="">
                            <p>Netherlands politicians just got a first-hand lesson about the dangers of deepfake videos. According to NL Times and De Volkskrant, the Dutch parliament's foreign affairs committee was fooled into holding a video call with someone using deepfake tech to impersonate Leonid Volkov (above), Russian opposition leader Alexei Navalny's chief of staff.

                                The perpetrator hasn't been named, but this wouldn't be the first incident. The same impostor had conversations with Latvian and Ukranian politicians, and approached political figures in Estonia, Lithuania and the UK.
                                
                                The country's House of Representatives said in a statement that it was "indignant" about the deepfake chat and was looking into ways it could prevent such incidents going forward.
                                
                                There doesn't appear to have been any lasting damage from the bogus video call. However, it does illustrate the potential damage from deepfake chats with politicians. A prankster could embarrass officials, while a state-backed actor could trick governments into making bad policy decisions and ostracizing their allies. Strict screening processes might be necessary to spot deepfakes and ensure that every participant is real.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Mother 'used deepfake to frame cheerleading rivals'</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/c.jpg" class="img-responsive img-centered" alt="">
                            <p>A mother allegedly used explicit deepfake photos and videos to try to get her teenage daughter's cheerleading rivals kicked off the team.

                                Raffaela Spone from Pennsylvania, US, reportedly sent the content - which showed members of the Victory Vipers team "naked, drinking and smoking" - to the coach.
                                
                                Deepfakes use artificial intelligence to doctor images and videos.
                                
                                Mrs Spone has been charged with multiple counts of harassment.
                                
                                She is also accused of sending abusive messages to the team, their parents and owners of the cheerleading gym, using fake phone numbers.
                                
                                The Hilltown Township Police Department in Bucks Country said it believed her daughter was unaware of the alleged incidents.
                                One victim's parents contacted police in July, saying their daughter had received harassing text messages from an anonymous number.

                                Two more families later came forward after receiving similar messages.
                                Mrs Spone is believed to have used the girls' social media accounts to generate the deepfake images.

                                Authorities traced the phone number that had sent the harassing text messages, which led them to a website that sells numbers to telemarketers.
                                
                                Police then followed the data to an IP address that was tracked to Mrs Spone's home.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Deepfake satellite images pose serious military and political challenges</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/d.jpg" class="img-responsive img-centered" alt="">
                            <p>It's well established that deepfake images of people are problematic, but it's now clearer that bogus satellite imagery could also represent a threat. The Verge reports that University of Washington-led researchers have developed a way to generate deepfake satellite photography as part of an effort to detect manipulated images.

                                The team used an AI algorithm to generate deepfakes by feeding the traits of learned satellite images into different base maps. They could use Tacoma's roads and building locations, for example (at top right in the picture below), but superimpose Beijing's taller buildings (bottom right) or Seattle's low-rises (bottom left). You can apply greenery, too. While the execution isn't flawless, it's close enough that scientists believe you might blame any oddities on low image quality. Lead author Bo Zhao was quick to note there could be positive uses for deepfaked satellite snapshots. You could simulate locations from the past to help understand climate change, study urban sprawl or predict how a region will evolve by filling in blanks.

                                However, there's little doubt the AI-created fakes could be used for misinformation. A hostile country could send falsified images to mislead military strategists — they might not notice a missing building or bridge that could be a valuable target. Fakes could also be used for political aims, such hiding evidence of atrocities or suppressing climate science.
                                
                                Researchers hope this work will help develop a system to catch satellite deepfakes in the same way that early work exists to spot human-oriented fakes. However, it might be a race against time — it didn't take long for early deepfake tech to escape from academia into the real world, and that might well happen again.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>FBI warns of the rise of 'deepfakes' in coming months</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/e.jpg" class="img-responsive img-centered" alt="">
                            <p>The FBI has issued a stark warning saying "malicious actors almost certainly will leverage synthetic content for cyber and foreign influence operations in the next 12-18 months."

                                "Synthetic content" refers to any manipulated or generated content across video, photo, text, and audio.
                                It also includes deepfakes, which use artificial intelligence to replace the likeness of one person with another.

                                In the statement issued March 10, the FBI said "Russian, Chinese, and Chinese-language actors are using synthetic profile images derived from GANs [generative adversarial networks]."
                                
                                They also pointed to an increase in the number of fake journalists and articles circulating online. While these journalists had a "robust online presence," their fraudulence can be uncovered by "basic fact-checks."
                                
                                Deepfakes have now entered popular culture and are easier than ever to make, becoming the subject of online memes but also of misinformation and abuse, particularly in the form of revenge porn.
                                
                                Former "fraud czar" of Google, Shuman Ghosemajumder, told Insider last year that deepfakes were likely to evolve and spread further, with "perfectly realistic" deepfakes in our near future.
                                
                                The FBI said they had "identified multiple campaigns which have leveraged synthetic content" since late 2019, and the number looks set to grow.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Thieves are now using AI deepfakes to trick companies into sending them money</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/f.jpg" class="img-responsive img-centered" alt="">
                            <p>It seems like every few days there’s another example of a convincing deepfake going viral or another free, easy-to-use piece of software (some even made for mobile) that can generate convincing video or audio that’s designed to trick someone into believing a piece of virtual artifice is real. But according to The Wall Street Journal, there may soon be serious financial and legal ramifications to the proliferation of deepfake technology.

                            The publication reported last week that a UK energy company’s chief executive was tricked into wiring €200,000 (or about $220,000 USD) to a Hungarian supplier because he believed his boss was instructing him to do so. But the energy company’s insurance firm, Euler Hermes Group SA, told the WSJ that a clever AI-equipped fraudster was using deepfake software to mimic the voice of the executive and demand his underling pay him within the hour.
                            
                            “The software was able to imitate the voice, and not only the voice: the tonality, the punctuation, the German accent,” a Euler Hermes spokesperson later told The Washington Post. The phone call was matched with an email, and the energy firm CEO obliged. The money is now gone, having been moved through accounts in Hungary and Mexico and dispersed around the world, the Post reports.
                            Later, after a second request from the thieves was made, the energy firm CEO called up his actual boss, only to find himself handling calls from both the fake and the real versions of the man simultaneously, which alerted the CEO to the ongoing theft. Euler Hermes declined to name the energy firm or its German parent company.

This may not be the first time this has happened. According to the Post, cybersecurity firm Symantec says it has come across at least three cases of deepfake voice fraud used to trick companies into sending money to a fraudulent account. Symantec told the Post that at least one of the cases, which appears to be distinct from the one Euler Hermes has confirmed, resulted in millions of dollars in losses.

The situation highlights the fraught nature of AI research, especially around the artificial creation of video and audio. While none of the big Silicon Valley companies with large, capable AI research institutions are openly developing deepfake video software, some are working diligently in the audio realm.

Google’s controversial Duplex service uses AI to mimic the voice of a real human being so that it can make phone calls on a user’s behalf. 
                            </p>
                           
        
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Deepfakes have the potential to disrupt financial markets</h2>
                            <hr class="star-primary">
                            <img src="/static/img/portfolio/g.jpg" class="img-responsive img-centered" alt="">
                            <p>Post
                                Deepfake technology is advancing fast, but researchers and technology companies are working on ways to detect synthetic media. Photo: ShutterstockDeepfake technology is advancing fast, but researchers and technology companies are working on ways to detect synthetic media. Photo: Shutterstock
                                Deepfake technology is advancing fast, but researchers and technology companies are working on ways to detect synthetic media. Photo: Shutterstock
                                Experts have been sounding the alarm about weak biometric data security for years. The problem has looked especially pernicious in China, where facial recognition is now a ubiquitous form of identification. Now the rise of deepfakes could be creating new problems, experts say.
                                Despite widespread concern about technology, which allows a person’s likeness to be imitated through audio and video, there are few real-world examples of hackers successfully exploiting it for monetary gain.
                                One of the big concerns has been the idea that deepfakes – to date mainly known for their use in celebrity nudes – could be used to trick facial recognition systems. So far, there is little evidence that this is something that scammers could easily pull off. But some are concerned about other potential problems related to deepfakes that go beyond just personal security to possibly eroding trust in the institutions that handle our money.
                                </p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- jQuery -->
    <script src="/static/js/jquery.js"></script>
    <!-- Bootstrap Core JavaScript -->
    <script src="/static/js/bootstrap.min.js"></script>
    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="/static/js/classie.js"></script>
    <script src="/static/js/cbpAnimatedHeader.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="/static/js/jqBootstrapValidation.js"></script>
    <script src="/static/js/contact_me.js"></script>
    <!-- Custom Theme JavaScript -->
    <script src="/static/js/freelancer.js"></script>
</body>
</html>
